{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lstm_modified",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHr3Hn6g31D0",
        "outputId": "8b89bef1-af01-4cfb-e1f8-a3922e02cb63"
      },
      "source": [
        #using google colab to read data from google drive
        "from google.colab import drive\r\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxP6DxuZ4CU4"
      },
      "source": [
        "import glob\r\n",
        "import pickle\r\n",
        "import numpy\r\n",
        "from music21 import *\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense\r\n",
        "from keras.layers import Dropout\r\n",
        "from keras.layers import LSTM\r\n",
        "from keras.layers import Activation\r\n",
        "from keras.layers import BatchNormalization as BatchNorm\r\n",
        "from keras.utils import np_utils\r\n",
        "from keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aq1m9R374NVb"
      },
      "source": [
        "def train_network():\r\n",
        "    \"\"\" Train a Neural Network to generate music \"\"\"\r\n",
        "    notes = get_notes()\r\n",
        "\r\n",
        "    # get amount of pitch names\r\n",
        "    n_vocab = len(set(notes))\r\n",
        "\r\n",
        "    network_input, network_output = prepare_sequences(notes, n_vocab)\r\n",
        "\r\n",
        "    model = create_network(network_input, n_vocab)\r\n",
        "\r\n",
        "    train(model, network_input, network_output)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-9kvwWI4PDP"
      },
      "source": [
        "def get_notes():\r\n",
        "    \"\"\" Get all the notes and chords from the midi files in the ./midi_songs directory \"\"\"\r\n",
        "    notes = []\r\n",
        "\r\n",
        "    for file in glob.glob(\"drive/My Drive/music/test1/*.mid\"):\r\n",
        "        midi = converter.parse(file)\r\n",
        "\r\n",
        "        print(\"Parsing %s\" % file)\r\n",
        "\r\n",
        "        notes_to_parse = None\r\n",
        "        \"\"\" maybe we can add a filter to keep only midi with time signiture 2/4 or 4/4\"\"\"\r\n",
        "\r\n",
        "        try: # file has instrument parts\r\n",
        "        \r\n",
        "            #directly read the midi melody at part 0\r\n",
        "            notes_to_parse = midi[0].notes\r\n",
        "        except: # file has notes in a flat structure\r\n",
        "            notes_to_parse = midi.flat.notes\r\n",
        "\r\n",
        "        for element in notes_to_parse:\r\n",
        "            if isinstance(element, note.Note):\r\n",
        "                #add duration\r\n",
        "                notes.append(str(element.pitch)+\"-\"+str(element.duration.quarterLength))\r\n",
        "            elif isinstance(element, chord.Chord):\r\n",
        "                #add duration\r\n",
        "                notes.append('#'.join(str(n) for n in element.normalOrder)+ \"-\" + str(element.duration.quarterLength))\r\n",
        "\r\n",
        "    with open('drive/My Drive/music/notes', 'wb') as filepath:\r\n",
        "        pickle.dump(notes, filepath)\r\n",
        "\r\n",
        "    return notes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbpGhTf84SEA"
      },
      "source": [
        "def prepare_sequences(notes, n_vocab):\r\n",
        "    \"\"\" Prepare the sequences used by the Neural Network \"\"\"\r\n",
        "    sequence_length = 100\r\n",
        "\r\n",
        "    # get all pitch names\r\n",
        "    pitchnames = sorted(set(item for item in notes))\r\n",
        "\r\n",
        "     # create a dictionary to map pitches to integers\r\n",
        "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\r\n",
        "\r\n",
        "    network_input = []\r\n",
        "    network_output = []\r\n",
        "\r\n",
        "    # create input sequences and the corresponding outputs\r\n",
        "    for i in range(0, len(notes) - sequence_length, 1):\r\n",
        "        sequence_in = notes[i:i + sequence_length]\r\n",
        "        sequence_out = notes[i + sequence_length]\r\n",
        "        network_input.append([note_to_int[char] for char in sequence_in])\r\n",
        "        network_output.append(note_to_int[sequence_out])\r\n",
        "\r\n",
        "    n_patterns = len(network_input)\r\n",
        "\r\n",
        "    # reshape the input into a format compatible with LSTM layers\r\n",
        "    network_input = numpy.reshape(network_input, (n_patterns, sequence_length, 1))\r\n",
        "    # normalize input\r\n",
        "    network_input = network_input / float(n_vocab)\r\n",
        "\r\n",
        "    network_output = np_utils.to_categorical(network_output)\r\n",
        "\r\n",
        "    return (network_input, network_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVqIcQef5FeL"
      },
      "source": [
        "def create_network(network_input, n_vocab):\r\n",
        "    \"\"\" create the structure of the neural network \"\"\"\r\n",
        "    model = Sequential()\r\n",
        "    model.add(LSTM(\r\n",
        "        512,\r\n",
        "        input_shape=(network_input.shape[1], network_input.shape[2]),\r\n",
        "        recurrent_dropout=0.3,\r\n",
        "        return_sequences=True\r\n",
        "    ))\r\n",
        "    model.add(LSTM(512, return_sequences=True, recurrent_dropout=0.3,))\r\n",
        "    model.add(LSTM(512))\r\n",
        "    model.add(BatchNorm())\r\n",
        "    model.add(Dropout(0.3))\r\n",
        "    model.add(Dense(256))\r\n",
        "    model.add(Activation('relu'))\r\n",
        "    model.add(BatchNorm())\r\n",
        "    model.add(Dropout(0.3))\r\n",
        "    model.add(Dense(n_vocab))\r\n",
        "    model.add(Activation('softmax'))\r\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\r\n",
        "\r\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgoCSdUE5MOc"
      },
      "source": [
        "def train(model, network_input, network_output):\r\n",
        "    \"\"\" train the neural network \"\"\"\r\n",
        "    filepath = \"drive/My Drive/music/weights.hdf5\"\r\n",
        "    checkpoint = ModelCheckpoint(\r\n",
        "        filepath,\r\n",
        "        monitor='loss',\r\n",
        "        verbose=0,\r\n",
        "        save_best_only=True,\r\n",
        "        mode='min'\r\n",
        "    )\r\n",
        "    callbacks_list = [checkpoint]\r\n",
        "\r\n",
        "    model.fit(network_input, network_output, epochs=10, batch_size=256, callbacks=callbacks_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nu6EQf745rp1",
        "outputId": "93b88c92-0f85-4be3-a37c-1a8710982087"
      },
      "source": [
        "if __name__ == '__main__':\r\n",
        "    train_network()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parsing drive/My Drive/music/test1/cs1-1pre.mid\n",
            "Parsing drive/My Drive/music/test1/cs1-2all.mid\n",
            "Parsing drive/My Drive/music/test1/cs1-3cou.mid\n",
            "Parsing drive/My Drive/music/test1/cs1-6gig.mid\n",
            "Parsing drive/My Drive/music/test1/cs2-1pre.mid\n",
            "Parsing drive/My Drive/music/test1/cs2-2all.mid\n",
            "Parsing drive/My Drive/music/test1/cs2-3cou.mid\n",
            "Parsing drive/My Drive/music/test1/cs2-4sar.mid\n",
            "Parsing drive/My Drive/music/test1/cs1-4sar.mid\n",
            "Parsing drive/My Drive/music/test1/cs2-6gig.mid\n",
            "Parsing drive/My Drive/music/test1/cs1-5men.mid\n",
            "Parsing drive/My Drive/music/test1/cs2-5men.mid\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Epoch 1/10\n",
            "28/28 [==============================] - 19s 689ms/step - loss: 5.6622\n",
            "Epoch 2/10\n",
            "28/28 [==============================] - 19s 681ms/step - loss: 5.3942\n",
            "Epoch 3/10\n",
            "28/28 [==============================] - 19s 679ms/step - loss: 5.1475\n",
            "Epoch 4/10\n",
            "28/28 [==============================] - 19s 677ms/step - loss: 4.8704\n",
            "Epoch 5/10\n",
            "28/28 [==============================] - 19s 690ms/step - loss: 4.5636\n",
            "Epoch 6/10\n",
            "28/28 [==============================] - 19s 679ms/step - loss: 4.3430\n",
            "Epoch 7/10\n",
            "28/28 [==============================] - 19s 685ms/step - loss: 4.1879\n",
            "Epoch 8/10\n",
            "28/28 [==============================] - 19s 691ms/step - loss: 4.0799\n",
            "Epoch 9/10\n",
            "28/28 [==============================] - 19s 691ms/step - loss: 4.0238\n",
            "Epoch 10/10\n",
            "28/28 [==============================] - 19s 687ms/step - loss: 3.9605\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
